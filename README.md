# [ChatCAD+: Towards a Reliable and Universal Interactive CAD using LLMs](https://arxiv.org/abs/2302.07257)

by Zihao Zhao\*, Sheng Wang\*, Jinchen Gu*,
Yitao Zhu*, Lanzhuju Mei,
Zixu Zhuang, Zhiming Cui, Qian Wang, Dinggang Shen

[![arXiv](https://img.shields.io/badge/ğŸ“ƒ-arXiv-ff69b4)](https://arxiv.org/abs/2302.07257)

<!-- ![webpage](https://img.shields.io/badge/ğŸ–¥-Website-9cf) -->

<div align="center">
  <img src="imgs/overview.png">
</div>

## Introduction

This repository provides the official implementation of some components of ChatCAD+:<br/>

- Modality identification <a src="https://colab.research.google.com/assets/colab-badge.svg" href="https://colab.research.google.com/drive/1mbBgkoyk4n_qAJasY5_cOAqg7I5WP1H7?usp=sharing">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
  </a>
- Interactive CAD of Chest X-rays
- LLM-based knowledge retrieval
- An easy-deploy local web ui (modified from [Gpt4All Web UI](https://github.com/ParisNeo/Gpt4All-webui.git) )

<!-- **[ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models](https://arxiv.org/abs/2302.07257)** <br/> -->

## æœ€è¿‘æ›´æ–°

- <img src="https://img.shields.io/badge/Version-0.0.3--alpha-brightgreen">(2023.4.18): P-Tuning & å¤šè½®å¯¹è¯ & æ¨¡å‹å¯é æ€§æå‡

## è®­ç»ƒæ•°æ®

| Dataset          | Department                | Language | Q&A | Chat | Number | Syn. | Size  | Weight                                                                     |
| ---------------- | ------------------------- | -------- | --- | ---- | ------ | ---- | ----- | -------------------------------------------------------------------------- |
| CMD.             | Surgical                  | CN       | âœ”   | Ã—    | 116K   | Ã—    | 52MB  |                                                                            |
|                  | Obstetrics and Gynecology | CN       | âœ”   | Ã—    | 229K   | Ã—    | 78MB  |                                                                            |
|                  | Pediatrics                | CN       | âœ”   | Ã—    | 117K   | Ã—    | 47MB  |                                                                            |
|                  | Internal Medicine         | CN       | âœ”   | Ã—    | 307K   | Ã—    | 102MB |                                                                            |
|                  | Andriatria                | CN       | âœ”   | Ã—    | 113K   | Ã—    | 44MB  |                                                                            |
|                  | Merged                    | CN       | âœ”   | Ã—    | 1.9M   | Ã—    |       | Doctor_GLM/ckpt                                                            |
| MedDialog        | Multiple                  | CN&EN    | âœ”   | âœ”    | 3.4M   | Ã—    | 1.5GB | [ptuning_weight](https://pan.baidu.com/s/1Yf56egVGwI0XN2iOLcEGSQ?pwd=r4p0) |
| ChatDoctor       | Multiple                  | EN       | âœ”   | Ã—    | 5.4K   | âœ”    | 2.9MB | Coming soon                                                                |
| HearlthcareMagic | Multiple                  | EN       | âœ”   | Ã—    | 200K   | Ã—    | 216MB | Coming soon                                                                |

https://github.com/Toyhom/Chinese-medical-dialogue-data

## ä½¿ç”¨

### lora

- æ˜¾å­˜ >= 13G ï¼ˆæœªé‡åŒ–ç‰ˆæœ¬ï¼‰
- pip install deep_training cpm_kernels icetk transformers>=4.26.1
- torch >= 1.12.0 (icetk ä¾èµ– cpu ç‰ˆ torch, å»ºè®®å…ˆå®‰è£… icetk åå®‰è£… gpu ç‰ˆ torch)
- lora çš„ finetune ä»£ç æ¥è‡ª https://github.com/ssbuild/chatglm_finetuning

å¯¹äº fp16 æ¨¡å‹ï¼Œç›´æ¥ä½¿ç”¨ Doctor_GLM/chat_lora.ipynbï¼Œç”±äºå®˜æ–¹æ›´æ–°äº† chatglm çš„æƒé‡ï¼Œæˆ‘ä»¬å°†è€ç‰ˆæƒé‡æ”¾åœ¨äº†
[old_pretrain_model](https://pan.baidu.com/s/1vuoBbOQVPJPAcurEfVRn7A?pwd=ahwc)
å¯ä»¥ä¸‹è½½åè§£å‹åˆ° old_pretrain_model ç›®å½•

é‡åŒ–çš„æ¨¡å‹æˆ‘ä»¬æ‰“äº†ä¸ªåŒ…ï¼Œä½¿ç”¨æ–¹ä¾¿ï¼Œä½†æ˜¯æ•ˆæœç›®å‰æ¥çœ‹å¾ˆæˆé—®é¢˜ï¼šINT4 éœ€è¦å¤§çº¦ 6G æ˜¾å­˜ï¼ŒINT8 éœ€è¦å¤§çº¦ 8G æ˜¾å­˜ï¼Œåœ¨ Doctor_GLM/chat_lora_quant.ipynb ä¸‹ä½¿ç”¨

```python
from load_quantization import load_int
tokenizer, model = load_int('DoctorGLM-6B-INT8-6merge-int8.pt',8)
response, history = model.chat(tokenizer,
                               "æˆ‘çˆ·çˆ·é«˜è¡€å‹å¯ä»¥å–å’–å•¡å—",
                               history=[],
                               max_length=2048)
print(response)
```

æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼š
[INT4](https://pan.baidu.com/s/1nHQ1EQ2OBuWCyBZKBnBHYw?pwd=x6l4) [INT8](https://pan.baidu.com/s/1v2hWl1dPnh8xoJzxtpbugw?pwd=y4hu)
é‡åŒ–æ–¹æ³•å‡ä¸ºåˆ†å±‚çš„çº¿æ€§é‡åŒ–ã€‚
ç›®å‰é‡åŒ–æ¨¡å‹çš„æ€§èƒ½**ä»æœ‰è¾ƒå¤§é—®é¢˜**ï¼ŒåæœŸæˆ‘ä»¬ä¼šå¯¹é‡åŒ–æ–¹æ³•å’Œæ¨¡å‹è¿›è¡Œæ›´æ–°

### p-tuningv2

å®˜æ–¹æä¾›äº† p-tuningv2 çš„å®ç°ï¼Œæ–°ç‰ˆæœ¬æƒé‡å¯ä»¥åœ¨ hugging face ä¸Šä¸‹è½½ï¼Œä¹Ÿå¯ä»¥ä»æˆ‘ä»¬çš„é“¾æ¥ä¸‹è½½ [pretrain_model](https://pan.baidu.com/s/1WaG-NQeXVR7BNZs_zlUFmQ?pwd=h88g)  
p-tuningv2 çš„æƒé‡åœ¨
[ptuning_weight](https://pan.baidu.com/s/1Yf56egVGwI0XN2iOLcEGSQ?pwd=r4p0) ï¼Œ ä¸‹è½½åè§£å‹åˆ° ckpt/ptuningv2 ç›®å½•ä¸‹, ç„¶åä½¿ç”¨ Doctor_GLM/chat_ptuning_v2.ipynbï¼Œæ ¹æ®éœ€è¦è°ƒæ•´ quantization_bit ä¸º 4 æˆ– 8

## æ¨¡å‹åœ¨çº¿éƒ¨ç½²

ä¸ºäº†æ–¹ä¾¿éƒ¨ç½²å¹¶éšæ—¶è°ƒæ•´æ¨¡å‹ç”Ÿæˆå›ç­”æ—¶çš„å‚æ•°ï¼Œæˆ‘ä»¬æä¾›äº†åŸºäº `Gradio` åº“çš„éƒ¨ç½²ä»£ç ï¼Œè·¯å¾„ä¸º `Doctor_GLM/gradio.ipynb`ã€‚è¿è¡Œä¹‹åï¼Œè®¿é—®æœ¬æœºçš„ 7860 æˆ–è€…ä»£ç å£°æ˜çš„å…¶ä»–ç«¯å£å³å¯ä»¥è¿è¡Œ Demoï¼Œæ¨¡å‹åœ¨ç”Ÿæˆå›ç­”æ—¶çš„å‚æ•°å¯ä»¥ç”±ç”¨æˆ·è‡ªç”±è°ƒæ§ã€‚è‹¥æƒ³è®©éƒ¨ç½²çš„æ¨¡å‹å¯ä»¥è¢«å±€åŸŸç½‘ä¹‹å¤–çš„å…¶ä»–ç”¨æˆ·è®¿é—®ï¼Œéœ€è¦å°† sharing è®¾ç½®ä¸º `True`ï¼ˆé»˜è®¤ä¸º`False`ï¼‰ã€‚éƒ¨ç½²ä¹‹åè¿è¡Œæ•ˆæœå¦‚ä¸‹æ‰€ç¤ºï¼š

<p align="center">
  <img src="imgs/gradio_demo.gif" width=1300px/>
  <br/>
</p>

## æœ€è¿‘æ›´æ–°

- <img src="https://img.shields.io/badge/Version-0.0.1--alpha-brightgreen"> (2023.4.3) åˆç‰ˆçš„æƒé‡ï¼Œæ¥è‡ª LoRA SFT 1 epcoh
- <img src="https://img.shields.io/badge/Version-0.0.2--alpha-brightgreen"> (2023.4.13) LoRA-INT4/8 é‡åŒ–æƒé‡ï¼Œä»¥åŠæˆ‘ä»¬å®éªŒå‘ç° LoRA ä¸€ç›´ä¼šä¸¢å¤±å¯¹è¯èƒ½åŠ›ï¼Œæ”¾å¼ƒè¯¥æ–¹å¼ï¼Œè½¬å‘ P-Tuning
- <img src="https://img.shields.io/badge/Version-0.0.3--alpha-brightgreen"> (2023.4.18) P-Tuning å¤šè½®å¯¹è¯æ•°æ®é›†è®­ç»ƒçš„æ–°æƒé‡å’Œ arxiv

## å³å°†åˆ°æ¥çš„æ›´æ–°

- [ ] <img src="https://img.shields.io/badge/Version-0.0.4--alpha-brightgreen"> (2023.4.21) å¯¹è¯ä¸­åŠ å…¥å‚è€ƒæ–‡çŒ®ï¼Œæ¨¡å‹ä¸Šä¼ åˆ° huggingface

ç¬¬ä¸€æ¬¡è¿è¡Œä¼šä¸‹è½½ chatGLM-6B æƒé‡, å¦‚æœå·²æœ‰ chatGLM-6B æƒé‡å¯ä»¥å°† data_utils.py é‡Œçš„è·¯å¾„ä¿®æ”¹ä¸ºè‡ªå·±çš„æƒé‡ç›®å½•

## ç»“æœç¤ºä¾‹

<p align="center">
  <img src="imgs/3_ret.png" width=1300px/>
  <br/>
</p>
æˆ‘ä»¬éšæœºè·‘äº†100ä¸ªç»“æœï¼Œåœ¨ ./resultsç›®å½•ä¸‹ï¼Œä¸¤ä»½jsonæ–‡ä»¶åˆ†åˆ«ä¸ºç”±ChatGLM, DoctorGLMå¾—åˆ°çš„ç»“æœï¼Œç›®å‰å­˜åœ¨å¤§é‡å¤è¯»æœºã€‚

## å¼€å‘è€…ç¾¤

<p align="left">
  <img src="imgs/11682312010_.pic.jpg" width=200px/>
</p>
DoctorGLMå¼€å‘è€…ç¾¤ï¼Œå¦‚æœä½ ä¹Ÿå¯¹åŸºäºChatGLMçš„åº”ç”¨å¼€å‘æ„Ÿå…´è¶£ï¼Œæ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„è®¨è®ºç»„ã€‚

## å¼•ç”¨

```
@article{xiong2023doctorglm,
      title={DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task},
      author={Honglin Xiong and Sheng Wang and Yitao Zhu and Zihao Zhao and Yuxiao Liu and Linlin Huang and Qian Wang and Dinggang Shen},
}
```
